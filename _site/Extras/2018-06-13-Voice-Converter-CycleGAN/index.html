<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
    <style type="text/css">
	    .article-wrap img{border-radius: 5px;}
		.titled-image figure{text-align: center;}
	</style>
	<meta charset="utf-8">
<title>Vinit Sheth's Website  &#8211; CycleGAN Voice Converter </title>
<meta name="description" content="">
<meta name="keywords" content="machine learning, deep learning, generative adversarial networks, computer vision">




<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="CycleGAN Voice Converter">
<meta property="og:description" content="Welcome to my site.">
<meta property="og:url" content="http://localhost:4000/Extras/2018-06-13-Voice-Converter-CycleGAN/">
<meta property="og:site_name" content="Vinit Sheth's Website">





<link rel="canonical" href="http://localhost:4000/Extras/2018-06-13-Voice-Converter-CycleGAN/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Vinit Sheth's Website Feed">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Google Webfonts -->
<link href='https://fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700|PT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>
<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.min.css">
<link rel="stylesheet" href="http://localhost:4000/assets/academicons.css" />

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<!-- Icons -->
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">

<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">

<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="192x192" href="http://localhost:4000/images/apple-icon-precomposed.png">

</head>

<body class="post">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="http://localhost:4000">Vinit Sheth's Website</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				<li><a href="http://localhost:4000/cv/" >Curriculum</a></li>
		        
				<li><a href="http://localhost:4000/projects/" >Projects</a></li>
		        
				<li><a href="http://localhost:4000/courses/" >Courses</a></li>
		        
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    
	<img src="http://localhost:4000/images//author_images/VinitSmall.jpg" class="bio-photo" alt="Vinit Sheth bio photo"></a>

<h3>Vinit Sheth</h3>
<p>Data Science , Machine Learning, Artificial Intelligence.</p>



<a href="http://linkedin.com/in/vinit-sheth" class="author-social" target="_blank"><i class="fa fa-linkedin-square"></i> LinkedIn</a>


<a href="http://github.com/vinitsheth" class="author-social" target="_blank"><i class="fa fa-github-square"></i> GitHub</a>









<a href="http://facebook.com/vinitgsheth" class="author-social" target="_blank"><i class="fa fa-facebook-square"></i> Facebook</a>
<a href="mailto:vsheth2@asu.edu" class="author-social" target="_blank"><i class="fa fa-envelope-square"></i> E-Mail</a>
<a href="https://drive.google.com/open?id=1ElcWvlcYgbx_Pw4amAY230AAM5meI6zQ" class="author-social" target="_blank"><i class="fa fa-file"></i>Resume</a>
  </div>
  <article>
    <div class="headline-wrap">
      
        <h1><a href="http://localhost:4000/Extras/2018-06-13-Voice-Converter-CycleGAN/" rel="bookmark" title="CycleGAN Voice Converter">CycleGAN Voice Converter</a></h1>
      
    </div><!--/ .headline-wrap -->
    <div class="article-wrap">
      <h2 id="introduction">Introduction</h2>

<p>Cycle-consistent adversarial networks (CycleGAN) has been widely used for image conversions. It turns out that it could also be used for voice conversion. This is an implementation of CycleGAN on human speech conversions. The neural network utilized 1D gated convolution neural network (Gated CNN) for generator, and 2D Gated CNN for discriminator. The model takes Mel-cepstral coefficients (<a href="https://github.com/eYSIP-2017/eYSIP-2017_Speech_Spoofing_and_Verification/wiki/Feature-Extraction-for-Speech-Spoofing">MCEPs</a>) (for spectral envelop) as input for voice conversions.</p>

<div class="titled-image">
<figure>
    <img src="http://localhost:4000/images/projects/2018-06-13-Voice-Converter-CycleGAN/neural_network_architecture.png" />
    <figcaption>Neural Network Architectures of CycleGAN-Based Voice Converter</figcaption>
</figure>
</div>

<h2 id="dependencies">Dependencies</h2>

<ul>
  <li>Python 3.5</li>
  <li>Numpy 1.14</li>
  <li>TensorFlow 1.8</li>
  <li>ProgressBar2 3.37.1</li>
  <li>LibROSA 0.6</li>
  <li>FFmpeg 4.0</li>
  <li><a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder">PyWorld</a></li>
</ul>

<h2 id="files">Files</h2>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.
├── convert.py
├── demo
├── download.py
├── figures
├── LICENSE.md
├── model.py
├── module.py
├── preprocess.py
├── README.md
├── train_log
├── train.py
└── utils.py
</code></pre></div></div>

<h2 id="usage">Usage</h2>

<h3 id="download-dataset">Download Dataset</h3>

<p>Download and unzip <a href="https://datashare.is.ed.ac.uk/handle/10283/2211">VCC2016</a> dataset to designated directories.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python download.py <span class="nt">--help</span>
usage: download.py <span class="o">[</span><span class="nt">-h</span><span class="o">]</span> <span class="o">[</span><span class="nt">--download_dir</span> DOWNLOAD_DIR] <span class="o">[</span><span class="nt">--data_dir</span> DATA_DIR]
                   <span class="o">[</span><span class="nt">--datasets</span> DATASETS]

Download CycleGAN voice conversion datasets.

optional arguments:
  <span class="nt">-h</span>, <span class="nt">--help</span>            show this <span class="nb">help </span>message and <span class="nb">exit</span>
  <span class="nt">--download_dir</span> DOWNLOAD_DIR
                        Download directory <span class="k">for </span>zipped data
  <span class="nt">--data_dir</span> DATA_DIR   Data directory <span class="k">for </span>unzipped data
  <span class="nt">--datasets</span> DATASETS   Datasets available: vcc2016
</code></pre></div></div>

<p>For example, to download the datasets to <code class="highlighter-rouge">download</code> directory and extract to <code class="highlighter-rouge">data</code> directory:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python download.py <span class="nt">--download_dir</span> ./download <span class="nt">--data_dir</span> ./data <span class="nt">--datasets</span> vcc2016
</code></pre></div></div>

<h3 id="train-model">Train Model</h3>

<p>To have a good conversion capability, the training would take at least 1000 epochs, which could take very long time even using a NVIDIA GTX TITAN X graphic card.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python train.py <span class="nt">--help</span>
usage: train.py <span class="o">[</span><span class="nt">-h</span><span class="o">]</span> <span class="o">[</span><span class="nt">--train_A_dir</span> TRAIN_A_DIR] <span class="o">[</span><span class="nt">--train_B_dir</span> TRAIN_B_DIR]
                <span class="o">[</span><span class="nt">--model_dir</span> MODEL_DIR] <span class="o">[</span><span class="nt">--model_name</span> MODEL_NAME]
                <span class="o">[</span><span class="nt">--random_seed</span> RANDOM_SEED]
                <span class="o">[</span><span class="nt">--validation_A_dir</span> VALIDATION_A_DIR]
                <span class="o">[</span><span class="nt">--validation_B_dir</span> VALIDATION_B_DIR]
                <span class="o">[</span><span class="nt">--output_dir</span> OUTPUT_DIR]
                <span class="o">[</span><span class="nt">--tensorboard_log_dir</span> TENSORBOARD_LOG_DIR]

Train CycleGAN model <span class="k">for </span>datasets.

optional arguments:
  <span class="nt">-h</span>, <span class="nt">--help</span>            show this <span class="nb">help </span>message and <span class="nb">exit</span>
  <span class="nt">--train_A_dir</span> TRAIN_A_DIR
                        Directory <span class="k">for </span>A.
  <span class="nt">--train_B_dir</span> TRAIN_B_DIR
                        Directory <span class="k">for </span>B.
  <span class="nt">--model_dir</span> MODEL_DIR
                        Directory <span class="k">for </span>saving models.
  <span class="nt">--model_name</span> MODEL_NAME
                        File name <span class="k">for </span>saving model.
  <span class="nt">--random_seed</span> RANDOM_SEED
                        Random seed <span class="k">for </span>model training.
  <span class="nt">--validation_A_dir</span> VALIDATION_A_DIR
                        Convert validation A after each training epoch. If <span class="nb">set
                        </span>none, no conversion would be <span class="k">done </span>during the training.
  <span class="nt">--validation_B_dir</span> VALIDATION_B_DIR
                        Convert validation B after each training epoch. If <span class="nb">set
                        </span>none, no conversion would be <span class="k">done </span>during the training.
  <span class="nt">--output_dir</span> OUTPUT_DIR
                        Output directory <span class="k">for </span>converted validation voices.
  <span class="nt">--tensorboard_log_dir</span> TENSORBOARD_LOG_DIR
                        TensorBoard log directory.
</code></pre></div></div>

<p>For example, to train CycleGAN model for voice conversion between <code class="highlighter-rouge">SF1</code> and <code class="highlighter-rouge">TM1</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python train.py <span class="nt">--train_A_dir</span> ./data/vcc2016_training/SF1 <span class="nt">--train_B_dir</span> ./data/vcc2016_training/TM1 <span class="nt">--model_dir</span> ./model/sf1_tm1 <span class="nt">--model_name</span> sf1_tm1.ckpt <span class="nt">--random_seed</span> 0 <span class="nt">--validation_A_dir</span> ./data/evaluation_all/SF1 <span class="nt">--validation_B_dir</span> ./data/evaluation_all/TM1 <span class="nt">--output_dir</span> ./validation_output <span class="nt">--tensorboard_log_dir</span> ./log
</code></pre></div></div>

<div class="titled-image">
<figure>
    <img src="http://localhost:4000/images/projects/2018-06-13-Voice-Converter-CycleGAN/discriminator_discriminator.png" />
    <img src="http://localhost:4000/images/projects/2018-06-13-Voice-Converter-CycleGAN/cycle_identity.png" />
    <figcaption>Training Losses of CycleGAN-Based Voice Converter</figcaption>
</figure>
</div>

<p>With <code class="highlighter-rouge">validation_A_dir</code>, <code class="highlighter-rouge">validation_B_dir</code>, and <code class="highlighter-rouge">output_dir</code> set, we could monitor the conversion of validation voices after each epoch using our bare ear.</p>

<h3 id="voice-conversion">Voice Conversion</h3>

<p>Convert voices using pre-trained models.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python convert.py <span class="nt">--help</span>
usage: convert.py <span class="o">[</span><span class="nt">-h</span><span class="o">]</span> <span class="o">[</span><span class="nt">--model_dir</span> MODEL_DIR] <span class="o">[</span><span class="nt">--model_name</span> MODEL_NAME]
                  <span class="o">[</span><span class="nt">--data_dir</span> DATA_DIR]
                  <span class="o">[</span><span class="nt">--conversion_direction</span> CONVERSION_DIRECTION]
                  <span class="o">[</span><span class="nt">--output_dir</span> OUTPUT_DIR]

Convert voices using pre-trained CycleGAN model.

optional arguments:
  <span class="nt">-h</span>, <span class="nt">--help</span>            show this <span class="nb">help </span>message and <span class="nb">exit</span>
  <span class="nt">--model_dir</span> MODEL_DIR
                        Directory <span class="k">for </span>the pre-trained model.
  <span class="nt">--model_name</span> MODEL_NAME
                        Filename <span class="k">for </span>the pre-trained model.
  <span class="nt">--data_dir</span> DATA_DIR   Directory <span class="k">for </span>the voices <span class="k">for </span>conversion.
  <span class="nt">--conversion_direction</span> CONVERSION_DIRECTION
                        Conversion direction <span class="k">for </span>CycleGAN. A2B or B2A. The
                        first object <span class="k">in </span>the model file name is A, and the
                        second object <span class="k">in </span>the model file name is B.
  <span class="nt">--output_dir</span> OUTPUT_DIR
                        Directory <span class="k">for </span>the converted voices.
</code></pre></div></div>

<p>To convert voice, put wav-formed speeches into <code class="highlighter-rouge">data_dir</code> and run the following commands in the terminal, the converted speeches would be saved in the <code class="highlighter-rouge">output_dir</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python convert.py <span class="nt">--model_dir</span> ./model/sf1_tm1 <span class="nt">--model_name</span> sf1_tm1.ckpt <span class="nt">--data_dir</span> ./data/evaluation_all/SF1 <span class="nt">--conversion_direction</span> A2B <span class="nt">--output_dir</span> ./converted_voices
</code></pre></div></div>
<p>The convention for <code class="highlighter-rouge">conversion_direction</code> is that the first object in the model filename is A, and the second object in the model filename is B. In this case, <code class="highlighter-rouge">SF1 = A</code> and <code class="highlighter-rouge">TM1 = B</code>.</p>

<h2 id="demo">Demo</h2>

<h3 id="vcc2016-sf1-and-tf2-conversion">VCC2016 SF1 and TF2 Conversion</h3>

<p>In the <code class="highlighter-rouge">demo</code> directory, there are voice conversions between the validation data of <code class="highlighter-rouge">SF1</code> and <code class="highlighter-rouge">TF2</code> using the pre-trained model.</p>

<p><br /></p>

<p><code class="highlighter-rouge">200001_SF1.wav</code> and <code class="highlighter-rouge">200001_TF2.wav</code> are real voices for the same speech from <code class="highlighter-rouge">SF1</code> and <code class="highlighter-rouge">TF2</code>, respectively.</p>

<p><br /></p>

<p><code class="highlighter-rouge">200001_SF1toTF2.wav</code> and <code class="highlighter-rouge">200001_TF2.wav</code> are the converted voice using the pre-trained model.</p>

<p><br /></p>

<p><code class="highlighter-rouge">200001_SF1toTF2_author.wav</code> is the converted voice from the <a href="http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/cyclegan-vc/">NTT</a> website for comparison with our model performance.</p>

<p><br /></p>

<p>The conversion performance is extremely good and the converted speech sounds real to me.</p>

<p><br /></p>

<p>Download the pre-trained SF1-TF2 conversion model and conversion of all the validation samples from <a href="https://drive.google.com/open?id=1SwiK9X3crXU4_-aM_-Sff1T82d6-1SEg">Google Drive</a>.</p>

<h4 id="ground-truth">Ground Truth</h4>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>SF1</th>
      <th>TF2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Speech 1</td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200001_SF1.wav" controls="" preload=""></audio></td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200001_TF2.wav" controls="" preload=""></audio></td>
    </tr>
    <tr>
      <td>Speech 2</td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200035_SF1.wav" controls="" preload=""></audio></td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200035_TF2.wav" controls="" preload=""></audio></td>
    </tr>
    <tr>
      <td>Speech 3</td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200042_SF1.wav" controls="" preload=""></audio></td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200042_TF2.wav" controls="" preload=""></audio></td>
    </tr>
  </tbody>
</table>

<h4 id="conversions">Conversions</h4>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>SF1 -&gt; TF2</th>
      <th>TF2 -&gt; SF1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Speech 1</td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200001_SF1toTF2.wav" controls="" preload=""></audio></td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200001_TF2toSF1.wav" controls="" preload=""></audio></td>
    </tr>
    <tr>
      <td>Speech 2</td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200035_SF1toTF2.wav" controls="" preload=""></audio></td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200035_TF2toSF1.wav" controls="" preload=""></audio></td>
    </tr>
    <tr>
      <td>Speech 3</td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200042_SF1toTF2.wav" controls="" preload=""></audio></td>
      <td><audio src="http://localhost:4000/downloads/projects/2018-06-13-Voice-Converter-CycleGAN/200042_TF2toSF1.wav" controls="" preload=""></audio></td>
    </tr>
  </tbody>
</table>

<h2 id="reference">Reference</h2>

<ul>
  <li>Takuhiro Kaneko, Hirokazu Kameoka. Parallel-Data-Free Voice Conversion Using Cycle-Consistent Adversarial Networks. 2017. (Voice Conversion CycleGAN)</li>
  <li>Wenzhe Shi, Jose Caballero, Ferenc Huszár, Johannes Totz, Andrew P. Aitken, Rob Bishop, Daniel Rueckert, Zehan Wang. Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network. 2016. (Pixel Shuffler)</li>
  <li>Yann Dauphin, Angela Fan, Michael Auli, David Grangier. Language Modeling with Gated Convolutional Networks. 2017. (Gated CNN)</li>
  <li>Takuhiro Kaneko, Hirokazu Kameoka, Kaoru Hiramatsu, Kunio Kashino. Sequence-to-Sequence Voice Conversion with Similarity Metric Learned Using Generative Adversarial Networks. 2017. (1D Gated CNN)</li>
  <li>Kun Liu, Jianping Zhang, Yonghong Yan. High Quality Voice Conversion through Phoneme-based Linear Mapping Functions with STRAIGHT for Mandarin. 2007. (Foundamental Frequnecy Transformation)</li>
  <li><a href="http://nbviewer.jupyter.org/gist/r9y9/ca05349097b2a3926ec77a02e62c6632">PyWorld and SPTK Comparison</a></li>
  <li><a href="https://github.com/anantzoid/Language-Modeling-GatedCNN">Gated CNN TensorFlow</a></li>
</ul>

<h2 id="github">GitHub</h2>

<p><a href="https://github.com/leimao/Voice_Converter_CycleGAN">Voice Converter CycleGAN</a></p>

      <hr />
      <footer role="contentinfo">
        <div class="article-author-bottom">
          
	<img src="http://localhost:4000/images//author_images/VinitSmall.jpg" class="bio-photo" alt="Vinit Sheth bio photo"></a>

<h3>Vinit Sheth</h3>
<p>Data Science , Machine Learning, Artificial Intelligence.</p>



<a href="http://linkedin.com/in/vinit-sheth" class="author-social" target="_blank"><i class="fa fa-linkedin-square"></i> LinkedIn</a>


<a href="http://github.com/vinitsheth" class="author-social" target="_blank"><i class="fa fa-github-square"></i> GitHub</a>









<a href="http://facebook.com/vinitgsheth" class="author-social" target="_blank"><i class="fa fa-facebook-square"></i> Facebook</a>
<a href="mailto:vsheth2@asu.edu" class="author-social" target="_blank"><i class="fa fa-envelope-square"></i> E-Mail</a>
<a href="https://drive.google.com/open?id=1ElcWvlcYgbx_Pw4amAY230AAM5meI6zQ" class="author-social" target="_blank"><i class="fa fa-file"></i>Resume</a>
        </div>
       <!-- <p class="byline"><strong>CycleGAN Voice Converter</strong> was published on <time datetime=""></time> and last modified on <time datetime="2018-06-13">June 13, 2018</time> by <a href="http://localhost:4000" title="About Vinit Sheth">Vinit Sheth</a>.</p> -->
      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  <footer>
    <span>&copy; 2019 Vinit Sheth. Powered by <a href="http://jekyllrb.com">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<!-- Old
<script>
  var _gaq = _gaq || [];
  var pluginUrl = 
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-133931159-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
-->
<!-- New -->
<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-133931159-1', 'auto');
  ga('send', 'pageview');

</script>



  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'vinitsheth-github-io'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

	        

</body>
</html>