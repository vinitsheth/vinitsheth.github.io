<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
    <style type="text/css">
	    .article-wrap img{border-radius: 5px;}
		.titled-image figure{text-align: center;}
	</style>
	<meta charset="utf-8">
<title>Vinit Sheth's Website  &#8211; Implementation of Gibbs Sampler </title>
<meta name="description" content="">
<meta name="keywords" content="Math, Statistics, Machine Learning">




<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Implementation of Gibbs Sampler">
<meta property="og:description" content="Welcome to my site.">
<meta property="og:url" content="http://localhost:4000/blog/Gibbs-Sampler/">
<meta property="og:site_name" content="Vinit Sheth's Website">





<link rel="canonical" href="http://localhost:4000/blog/Gibbs-Sampler/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Vinit Sheth's Website Feed">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Google Webfonts -->
<link href='https://fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700|PT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>
<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.min.css">
<link rel="stylesheet" href="http://localhost:4000/assets/academicons.css" />

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<!-- Icons -->
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">

<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">

<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="192x192" href="http://localhost:4000/images/apple-icon-precomposed.png">

</head>

<body class="post">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="http://localhost:4000">Vinit Sheth's Website</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				<li><a href="http://localhost:4000/cv/" >Curriculum</a></li>
		        
				<li><a href="http://localhost:4000/projects/" >Projects</a></li>
		        
				<li><a href="http://localhost:4000/courses/" >Courses</a></li>
		        
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    
	<img src="http://localhost:4000/images//author_images/VinitSmall.jpg" class="bio-photo" alt="Vinit Sheth bio photo"></a>

<h3>Vinit Sheth</h3>
<p>Data Science , Machine Learning, Artificial Intelligence.</p>



<a href="http://linkedin.com/in/vinit-sheth" class="author-social" target="_blank"><i class="fa fa-linkedin-square"></i> LinkedIn</a>


<a href="http://github.com/vinitsheth" class="author-social" target="_blank"><i class="fa fa-github-square"></i> GitHub</a>









<a href="http://facebook.com/vinitgsheth" class="author-social" target="_blank"><i class="fa fa-facebook-square"></i> Facebook</a>
<a href="mailto:vsheth2@asu.edu" class="author-social" target="_blank"><i class="fa fa-envelope-square"></i> E-Mail</a>
<a href="https://drive.google.com/open?id=1ElcWvlcYgbx_Pw4amAY230AAM5meI6zQ" class="author-social" target="_blank"><i class="fa fa-file"></i>Resume</a>
  </div>
  <article>
    <div class="headline-wrap">
      
        <h1><a href="http://localhost:4000/blog/Gibbs-Sampler/" rel="bookmark" title="Implementation of Gibbs Sampler">Implementation of Gibbs Sampler</a></h1>
      
    </div><!--/ .headline-wrap -->
    <div class="article-wrap">
      <h3 id="introduction">Introduction</h3>

<p>The basic algorithm for Gibbs Sampler is as follows.</p>
<center><img width="600" height="600" src="http://localhost:4000/images/blog/2017-06-13-Gibbs-Sampler/gibbs_sampler_algorithm.png" /></center>

<p>From my understanding, there are two applications of Gibbs sampler as well as general Monte Carlo Markov Chain (MCMC) samplers.</p>

<p><br /></p>

<p>The first application is to sample multivariable data point from a certain distributions, which is relatively easy.</p>
<center><img width="600" height="600" src="http://localhost:4000/images/blog/2017-06-13-Gibbs-Sampler/gibbs_sampling.jpg" /></center>

<p>If you want to sample data from a bivariate normal distribtution, here is what you can do using Gibbs sampler.</p>
<center><img width="600" height="600" src="http://localhost:4000/images/blog/2017-06-13-Gibbs-Sampler/gibbs_sampler_bivariate_normal.jpg" /></center>

<p>The second application is to do Bayesian Inference of the parameters behind a certain dataset, which is relatively difficult to some extent, and requires more expertise in math. This is what I am going to emphasize on in this blog article.</p>

<h3 id="gibbs-sampler-inference">Gibbs Sampler Inference</h3>

<p><a href="/downloads/blog/2017-06-13-Gibbs-Sampler/GibbsSampling.pdf">Here</a> is a very good problem example of Gibbs Sampler Bayesian Inference. The author also provided the implementation <a href="http://www2.bcs.rochester.edu/sites/jacobslab/cheat_sheets.html">code</a> for solving the problem using Gibbs Sampler, which you could also download it <a href="http://localhost:4000/downloads/blog/2017-06-13-Gibbs-Sampler/GibbsSampling.code.py">here</a>.</p>

<p><br /></p>

<p>The original code is a little bit confusing, although it is correct. I rewrote and annotated it so that one can understand it more easily. You may download my code <a href="http://localhost:4000/downloads/blog/2017-06-13-Gibbs-Sampler/GibbsSampling.code.lei.py">here</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Gibbs sampler for the change-point model described in a Cognition cheat sheet titled "Gibbs sampling."</span>
<span class="c"># This is a Python implementation of the procedure at http://www.cmpe.boun.edu.tr/courses/cmpe58n/fall2009/</span>
<span class="c"># Written by Ilker Yildirim, September 2012.</span>
<span class="c"># Revised and Annotated by Lei Mao, June 2017.</span>
<span class="c"># dukeleimao@gmail.com</span>

<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">uniform</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">poisson</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">log</span><span class="p">,</span><span class="n">exp</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">multinomial</span>

<span class="c"># fix the random seed for replicability.</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c"># Generate data</span>

<span class="c"># Hyperparameters</span>
<span class="c"># Number of total data points</span>
<span class="n">N</span><span class="o">=</span><span class="mi">50</span>

<span class="c"># Change-point: where the intensity parameter changes.</span>
<span class="c"># The threhold point of two sets of data points</span>
<span class="c"># n &lt;= N</span>
<span class="c"># Here we set n = 23</span>
<span class="n">n</span><span class="o">=</span><span class="mi">23</span>
<span class="k">print</span> <span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c"># Intensity values</span>
<span class="c"># lambda1 for generating the first set of data from Poisson distribution</span>
<span class="c"># Here we set lambda1 = 2</span>
<span class="n">lambda1</span><span class="o">=</span><span class="mi">2</span>
<span class="c"># lambda2 for generating the second set of data from Poisson distribution</span>
<span class="c"># Here we set lambda1 = 8</span>
<span class="n">lambda2</span><span class="o">=</span><span class="mi">8</span>

<span class="c"># Generating observations x, consisting x_1 ... x_N</span>
<span class="n">lambdas</span><span class="o">=</span><span class="p">[</span><span class="n">lambda1</span><span class="p">]</span><span class="o">*</span><span class="n">n</span>
<span class="n">lambdas</span><span class="p">[</span><span class="n">n</span><span class="p">:</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">lambda2</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="n">n</span><span class="p">)</span>

<span class="n">x</span><span class="o">=</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">lambdas</span><span class="p">)</span>

<span class="c"># Make one big subplots and put everything in it.</span>
<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span><span class="n">ax2</span><span class="p">,</span><span class="n">ax3</span><span class="p">,</span><span class="n">ax4</span><span class="p">,</span><span class="n">ax5</span><span class="p">)</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="c"># Plot the data</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">),</span><span class="n">x</span><span class="p">,</span><span class="n">linefmt</span><span class="o">=</span><span class="s">'b-'</span><span class="p">,</span> <span class="n">markerfmt</span><span class="o">=</span><span class="s">'bo'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">),</span><span class="n">lambdas</span><span class="p">,</span><span class="s">'r--'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Counts'</span><span class="p">)</span>

<span class="c"># Given the dataset, our mission is to model this dataset</span>
<span class="c"># Our hypothesis is that the dataset consists two set of data, each set of the</span>
<span class="c"># data satisfies Poisson distribution (You can also model the data using other </span>
<span class="c"># distributions, say, Normal distribution, to see whether it works).</span>
<span class="c"># We need to infer three parameters in the model using the dataset we have. </span>
<span class="c"># 1. The threhold point of two sets of data points n</span>
<span class="c"># 2. lambda1 for the first Poisson distribution dataset</span>
<span class="c"># 3. lambda2 for the second Poisson distribution dataset</span>

<span class="c"># Gibbs sampler</span>
<span class="c"># Number of parameter sets we are going to sample</span>
<span class="n">E</span><span class="o">=</span><span class="mi">5200</span>
<span class="c"># Number of parameter sets at the beginning of sampling we need to remove</span>
<span class="c"># This is called "BURN-IN"</span>
<span class="n">BURN_IN</span><span class="o">=</span><span class="mi">200</span>

<span class="c"># Initialize the chain</span>
<span class="c"># Model n to be uniformly distributed from 0 to N</span>
<span class="n">n</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">()</span><span class="o">*</span><span class="n">N</span><span class="p">))</span>
<span class="c"># Model lambda to satisfy gamma distribution</span>
<span class="c"># We mannually set the gamma distribution parameter</span>
<span class="n">a</span><span class="o">=</span><span class="mi">2</span>
<span class="n">b</span><span class="o">=</span><span class="mf">0.2</span>
<span class="n">lambda1</span><span class="o">=</span><span class="n">gamma</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="n">b</span><span class="p">)</span>
<span class="n">lambda2</span><span class="o">=</span><span class="n">gamma</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="n">b</span><span class="p">)</span>

<span class="c"># My understanding is that the model of these three variables should at least </span>
<span class="c"># sample the true values of the variables with probablities larger than 0 (here</span>
<span class="c"># the uniform distribution could sample variables from 0 to N, gamma</span>
<span class="c"># distribution could sample variables greater or equal to 0), and the posterior</span>
<span class="c"># conditionals of these three could be calculated easily using Bayesian </span>
<span class="c"># Equations. Finally, this posterior probability distribution should be easy to </span>
<span class="c"># use for sampling.</span>

<span class="c"># Store the samples</span>
<span class="n">chain_n</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">E</span><span class="o">-</span><span class="n">BURN_IN</span><span class="p">))</span>
<span class="n">chain_lambda1</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">E</span><span class="o">-</span><span class="n">BURN_IN</span><span class="p">))</span>
<span class="n">chain_lambda2</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">E</span><span class="o">-</span><span class="n">BURN_IN</span><span class="p">))</span>

<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">E</span><span class="p">):</span>
	<span class="k">print</span> <span class="s">"At iteration "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
	<span class="c"># sample lambda1 and lambda2 from their posterior conditionals, Equation 8 and Equation 9, respectively.</span>
	<span class="n">lambda1</span><span class="o">=</span><span class="n">gamma</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="n">b</span><span class="p">))</span>
	<span class="n">lambda2</span><span class="o">=</span><span class="n">gamma</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">a</span><span class="o">+</span><span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">n</span><span class="p">:</span><span class="n">N</span><span class="p">]),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="n">n</span><span class="o">+</span><span class="n">b</span><span class="p">))</span>
	
	<span class="c"># sample n, Equation 10</span>
	<span class="n">mult_n</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
		<span class="n">mult_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span><span class="p">])</span><span class="o">*</span><span class="n">log</span><span class="p">(</span><span class="n">lambda1</span><span class="p">)</span><span class="o">-</span><span class="n">i</span><span class="o">*</span><span class="n">lambda1</span><span class="o">+</span><span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">N</span><span class="p">])</span><span class="o">*</span><span class="n">log</span><span class="p">(</span><span class="n">lambda2</span><span class="p">)</span><span class="o">-</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="n">i</span><span class="p">)</span><span class="o">*</span><span class="n">lambda2</span>
	<span class="n">mult_n</span><span class="o">=</span><span class="n">exp</span><span class="p">(</span><span class="n">mult_n</span><span class="o">-</span><span class="nb">max</span><span class="p">(</span><span class="n">mult_n</span><span class="p">))</span>
	<span class="n">n</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">mult_n</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">mult_n</span><span class="p">),</span><span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">==</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
	
	<span class="c"># store</span>
	<span class="k">if</span> <span class="n">e</span><span class="o">&gt;=</span><span class="n">BURN_IN</span><span class="p">:</span>
		<span class="n">chain_n</span><span class="p">[</span><span class="n">e</span><span class="o">-</span><span class="n">BURN_IN</span><span class="p">]</span><span class="o">=</span><span class="n">n</span>
		<span class="n">chain_lambda1</span><span class="p">[</span><span class="n">e</span><span class="o">-</span><span class="n">BURN_IN</span><span class="p">]</span><span class="o">=</span><span class="n">lambda1</span>
		<span class="n">chain_lambda2</span><span class="p">[</span><span class="n">e</span><span class="o">-</span><span class="n">BURN_IN</span><span class="p">]</span><span class="o">=</span><span class="n">lambda2</span>
		

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">chain_lambda1</span><span class="p">,</span><span class="s">'b'</span><span class="p">,</span><span class="n">chain_lambda2</span><span class="p">,</span><span class="s">'g'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'$</span><span class="err">\</span><span class="s">lambda$'</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">chain_lambda1</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'$</span><span class="err">\</span><span class="s">lambda_1$'</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">12</span><span class="p">])</span>
<span class="n">ax4</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">chain_lambda2</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'g'</span><span class="p">)</span>
<span class="n">ax4</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">12</span><span class="p">])</span>
<span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'$</span><span class="err">\</span><span class="s">lambda_2$'</span><span class="p">)</span>
<span class="n">ax5</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">chain_n</span><span class="p">,</span><span class="mi">50</span><span class="p">)</span>
<span class="n">ax5</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'n'</span><span class="p">)</span>
<span class="n">ax5</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">50</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>The output is as follows. The infered parameters matches the ones used for generating the data pretty well. The infered n equals exactly 23. The infered lambda1 and lambda2 were also centered at 2 and 8, respectively.</p>

<center><img width="1200" height="1200" src="http://localhost:4000/images/blog/2017-06-13-Gibbs-Sampler/gibbs_sampler_figure_1.png" /></center>

<p>It should be noted that if you changed the parameters in the model (here, a and b for the gamma distribution), or even changed the model (say, uniform distribution to normal distribution, gamma distribution to normal distribution). The good infered parameters might not match the “real ones” exactly, but they should be very close.</p>

<p><br /></p>

<p>Here, if I change a from 2 to 5, change b from 0.2 to 10. The infered n equals around 23. However, the infered lambda1 and lambda2 were centered at 1.5 and 6, respectively. This is very bad, because for lambda2, the true value, which is 8, was not even sampled once.</p>

<center><img width="1200" height="1200" src="http://localhost:4000/images/blog/2017-06-13-Gibbs-Sampler/gibbs_sampler_figure_2.png" /></center>

<p>So, how can we find there is a problem here, given we do not know the true parameters in real problems.</p>

<p><br /></p>

<p>I have an idea but I am not sure whether this is correct in principle, or whether there is any theory to support this.</p>

<p><br /></p>

<p>For a = 2, b = 0.2, the probability density function of gamma distribution (lambda1, lambda2 ~ Gamma(a = 2, b = 1/0.2)) is like this (click <a href="http://localhost:4000/downloads/blog/2017-06-13-Gibbs-Sampler/gamma_pdf.py">here</a> to download the code for the probability density function plot of gamma distribution).</p>

<center><img width="500" height="500" src="http://localhost:4000/images/blog/2017-06-13-Gibbs-Sampler/gamma_pdf_figure_1.png" /></center>

<p>After Gibbs sampling, we know that the priors for lambda1 and lambda2 (lambda1 = 2, lambda2 = 8) are very high.</p>

<p><br /></p>

<p>For a = 5, b = 10, the probability density function of gamma distribution (lambda1, lambda2 ~ Gamma(a = 5, b = 1/10)) is like this.</p>

<center><img width="500" height="500" src="http://localhost:4000/images/blog/2017-06-13-Gibbs-Sampler/gamma_pdf_figure_2.png" /></center>

<p>After Gibbs sampling, we know that the priors for lambda1 and lambda2 (lambda1 = 1.5, lambda2 = 6) are extremely low.</p>

<p><br /></p>

<p>Although I am not sure whether there is any correlation between the prior probabilities and the “correctness of inference”, it should be noted that, even with the inference using a = 5 and b = 10, I can still reconstruct the dataset very well, which means that the choice of these model parameters might not have significant impact on our real studies.</p>

      <hr />
      <footer role="contentinfo">
        <div class="article-author-bottom">
          
	<img src="http://localhost:4000/images//author_images/VinitSmall.jpg" class="bio-photo" alt="Vinit Sheth bio photo"></a>

<h3>Vinit Sheth</h3>
<p>Data Science , Machine Learning, Artificial Intelligence.</p>



<a href="http://linkedin.com/in/vinit-sheth" class="author-social" target="_blank"><i class="fa fa-linkedin-square"></i> LinkedIn</a>


<a href="http://github.com/vinitsheth" class="author-social" target="_blank"><i class="fa fa-github-square"></i> GitHub</a>









<a href="http://facebook.com/vinitgsheth" class="author-social" target="_blank"><i class="fa fa-facebook-square"></i> Facebook</a>
<a href="mailto:vsheth2@asu.edu" class="author-social" target="_blank"><i class="fa fa-envelope-square"></i> E-Mail</a>
<a href="https://drive.google.com/open?id=1ElcWvlcYgbx_Pw4amAY230AAM5meI6zQ" class="author-social" target="_blank"><i class="fa fa-file"></i>Resume</a>
        </div>
       <!-- <p class="byline"><strong>Implementation of Gibbs Sampler</strong> was published on <time datetime="2017-06-13T00:00:00-07:00">June 13, 2017</time> and last modified on <time datetime="2017-06-13">June 13, 2017</time> by <a href="http://localhost:4000" title="About Vinit Sheth">Vinit Sheth</a>.</p> -->
      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  <footer>
    <span>&copy; 2019 Vinit Sheth. Powered by <a href="http://jekyllrb.com">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<!-- Old
<script>
  var _gaq = _gaq || [];
  var pluginUrl = 
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-133931159-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
-->
<!-- New -->
<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-133931159-1', 'auto');
  ga('send', 'pageview');

</script>



  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'vinitsheth-github-io'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

	        

</body>
</html>